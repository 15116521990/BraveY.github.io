<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis源码阅读——SDS]]></title>
    <url>%2F2019%2F03%2F22%2FRedis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E2%80%94%E2%80%94SDS%2F2019-03-22-Redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E2%80%94%E2%80%94SDS%2F</url>
    <content type="text"><![CDATA[Redis源码阅读——SDS参考Redis设计与实现 以及网上博客阅读Redis源码。 SDS相关知识点见读书笔记。 创建和销毁为了能够对sds进行相关API的测试，因此把sds模块单独提出来。阅读Redis的Makefile发现，编译sds模块需要的源文件包括sds.c, sds.h zmalloc.c 123test-sds: sds.c sds.h $(REDIS_CC) sds.c zmalloc.c -DSDS_TEST_MAIN $(FINAL_LIBS) -o /tmp/sds_test /tmp/sds_test 但是实际编译后会发现会报很多函数未定义的错。原因是redis源码里面sds的内存分配、释放、重分配这些函数是封装成zmalloc,zfee这些函数的，只单纯的把zmalloc.c提取出来是远远不够的。后面发现redis的作者已经把sds给单独提出来了。包括三个源文件sds.c,sds.h,sdsalloc.h 因此执行如下操作即可单独把redis的sds模块提取出来。 提取sds模块 新建redis_sds测试目录 选择合适的目录下新建 mkdir redis_sds 复制源文件至redis_sds目录下 在redis源码的src目录下执行： cp sds.c ~/redis_sds/ cp sds.h ~/redis_sds/ cp sdsalloc.h ~/redis_sds/ 修改sdsalloc.h 复制过来的sdsalloc.h 将sds模块的内存函数封装为使用zmalloc函数。为了简化处理直接使用libc的malloc函数来进行内存管理，同时将zmalloc.h给注释掉。 1234//#include "zmalloc.h"#define s_malloc malloc#define s_realloc realloc#define s_free free 新建主函数 新建主函数sds_test.c 1234567891011121314#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include "sds.c"//#include "sds.h"int main(int argc, char *argv[]) &#123; sds s = sdsnew("Hello World!"); printf("Length:%d, Type:%d\n", sdslen(s), sdsReqType(sdslen(s))); s = sdscat(s, "The length of this sentence is greater than 32 bytes"); printf("Length:%d, Type:%d\n", sdslen(s), sdsReqType(sdslen(s))); sdsfree(s); return 0;&#125; 直接include sds.c 即可，因为如果#include “sds.h” 的话，sdsReqType这个函数并没有在sds.h里面声明，而且因为sdsReqType的申明是： static inline char sdsReqType(size_t string_size) { 有static限制所以不能在sds.h中先声明，所以为了简单就直接#include 了sds.c了 编译 为了方便重复编译，所以写了个简单的Makefile。 12test : sds_test.c sds.h sds.c sdsalloc.h gcc -o sdstest sds_test.c 只需要编译sds_test.c 即可。因为sds_test.c 里面是直接#include sds.c 了所以再 gcc -o sdstest sds_test.c sds.c 会将sds.c 里面的函数重复编译两次，造成Multiple definition 问题。 之后只需要执行make命令就可以生成可执行文件sdstest。 执行后输出为： 123./sdstest Length:12, Type:0Length:64, Type:1 sds的创建通过sdsnew 来创建了一个sds。sdsnew源码为： 123456/* Create a new sds string starting from a null terminated C string. */sds sdsnew(const char *init) &#123; //使用？条件判断符来简化if语句对NULL的判断，直接使用strlen来返回字符指针的长度。 size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125; 需要注意的是字符数组和字符指针是有区别的：字符指针的数据是存放在进程的虚拟地址空间的程序代码和数据段，是只读的不能修改。字符数组存放的字符串数据是存放在用户栈的，是可以更改的。且字符指针的数据没有”\0”这个结束符。 参考博客讲的很好：https://blog.csdn.net/on_1y/article/details/13030439 sdsnew 通过把字符串长度和字符串传递给sdsnewlen，来完成创建。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/* Create a new sds string with the content specified by the 'init' pointer * and 'initlen'. * If NULL is used for 'init' the string is initialized with zero bytes. * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = n("abc",3); * * You can print the string with printf() as there is an implicit \0 at the * end of the string. However the string is binary safe and can contain * \0 characters in the middle, as the length is stored in the sds header. */sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); //返回字符串对应的type /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ /* 空字符串使用sdshdr8来存储，而不是sdshdr5,（虽然长度小于32），因为sdshdr5不适合扩容。 */ if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); // 返回对应类型的sdsheader长度。 unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1); // 申请头部+字符串+NULL的大小。(单位为byte) if (!init) memset(sh, 0, hdrlen+initlen+1); // 将sh后面对应大小的字节全部置为0； if (sh == NULL) return NULL; s = (char*)sh+hdrlen; //s指针指向字符串的首字节。 fp = ((unsigned char*)s)-1; // fp指针指向flag switch(type) &#123; // 初始化sdshdr case SDS_TYPE_5: &#123; *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS);// 设置flag这个字节的具体值 break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); // 获取header指针sh sh-&gt;len = initlen; //header中len的初始 sh-&gt;alloc = initlen; //header 中alloc的初试 *fp = type; //flag 的初始。 break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); // 将字符串拷贝到s(也就是buf数组) s[initlen] = '\0'; //在字符串后面添加终止符 return s;&#125; char type = sdsReqType(initlen); 获取sds类型，源码分析在读书笔记里面有记录。源码为 12345678910111213static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) // string_size &lt; 2^5 return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) //string_size &lt; 2^8 return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) //string_size &lt; 2^16 return SDS_TYPE_16;#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) //string_size &lt; 2^32 return SDS_TYPE_32;#endif return SDS_TYPE_64; &#125; 采用左移来计算对应多少位的范围，而不是用2^5 这样的乘法。直接移位比使用幂来计算快很多。 1&lt;&lt;5 计算出来就是2^5 次方。1是int型，4byte32位。最低8bit位的二进制为：00000001 左移5位后变成了：00100000 对应的十进制既是32。 计算n个bit位的最大值：(1&lt;&lt;n) -1 但是需要注意位数不够的情况。因为1是int型，只有32个bit。所以在左移32个bit时，需要使用long long int型。用1ll来表示，此时1ll为64个bit。 还得考虑机器是否为64位机器，在32位机器上LONG_MAX = 2147483647L，64位机器上LONG_MAX = 9223372036854775807L 。不论32位机器还是64位机器上 LLONG_MAX 都是9223372036854775807L 。所以当LONG_MAX == LLONG_MAX 说明字长为64bit。加上条件编译，说明在32位机器上不使用sdshdr32而直接跳到了sdshdr64，仅仅在64位机器上使用sdshdr32。原因是什么？还没想通 123456789101112131415static inline int sdsHdrSize(char type) &#123; switch(type&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return sizeof(struct sdshdr5); case SDS_TYPE_8: return sizeof(struct sdshdr8); case SDS_TYPE_16: return sizeof(struct sdshdr16); case SDS_TYPE_32: return sizeof(struct sdshdr32); case SDS_TYPE_64: return sizeof(struct sdshdr64); &#125; return 0;&#125; 因为struct里面的buf数组是柔性数组，计算结构体的大小的时候不会计算在内。 memset(sh, 0, hdrlen+initlen+1); memset函数会将sh中当前位置后面的hdrlen+initlen+1个字节全部置于0。 注意sh指向的是hdrlen+initlen+1 个字节的首个字节。（sh指针存储的地址就是首个字节的地址。） memset源码为：https://github.com/gcc-mirror/gcc/blob/master/libgcc/memset.c 1234567891011/* Public domain. */#include &lt;stddef.h&gt;void *memset (void *dest, int val, size_t len)&#123; unsigned char *ptr = dest; // 用char来限定每次指针+1只移动一个字节。 while (len-- &gt; 0) *ptr++ = val; return dest;&#125; 假设hdrlen+initlen+1 为8 ，经过memset后，从sh首字节开始共有8个字节都被置为0。 指针的类型时用来确定指针需要从寻址多少个字节。比如int * 指针说明指针存储的地址朝后面偏移3个字节才是这个int类型的所有数据。即指针存储的地址时起点，而终点是由类型来确定的。 随后用switch语句对不同类型的sdshdr设置初始值。 首先是sdshdr5 *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS) 使用移位和或操作的方式来对8个bit位赋值。(不得不感慨这些操作真的是太巧妙了) 假设initlen为3。则initlen的二进制为0000 0011（应该是8byte（64位机器）或者4byte（32位机器），为了简单用1byte的二进制表示）而SDS_TYPE_BITS 为3。所以先将initlen 左移3个bit 变成0000 0001 1000(共有8byte或者4byte)。再与type进行或运算。type为0000 0000 进行或运算后，得到的内容是8bit的，因为type是char类型，即0001 1000 。 其他sdshdr类型的设置都差不多，详解下sdshdr8. SDS_HDR_VAR(8,s) SDS_HDR_VAR 是个宏定义的函数 #define SDS_HDR_VAR(T,s) struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T))); 采用宏定义函数的好处是 能够减少额外的开销 因为如果写成普通函数的话，函数的调用会在用户栈开辟空间，形参压栈，返回时还需要释放栈，可想而知的开销。使用宏定义函数则在代码规模和速度方面都比函数更胜一筹。宏定义的本质就是替换，所以在使用宏定义函数的地方，执行的时候相当于是在直接执行struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T))) 这句代码 函数的参数必须被声明为一种特定的类型，所以它只能在类型合适的表达式上使用。而宏定义则可以用于整形、长整形、单浮点型、双浮点型以及其他任何可以用“&gt;”操作符比较值大小的类型，也就是说，宏是与类型无关的。（有点C++模版类的感觉） 宏定义函数中的## 是（token-pasting）符号连接操作符 直接将形参T链接到sdshdr上面。也就是sdshdrT。 所以这句代码也就很简单了，将字符串指针s向后移动header的大小，也就得到了header的指针。（不过有个疑问是为什么还要重新获取headr的地址，最开始不就是指向了header吗？，难道memset是直接对sh进行操作的？测试过了，memset不会修改sh的地址，所以应该是为了再次确保sh一定指向header） memcpy(s, init, initlen); 函数将init的前initlen个字符拷贝给s。 memcpy源码为： 123456789101112/* Public domain. */#include &lt;stddef.h&gt;void *memcpy (void *dest, const void *src, size_t len)&#123; char *d = dest; const char *s = src; while (len--) *d++ = *s++; return dest;&#125; 整个过程中的三个指针sh,s,fp对应关系如下图 销毁销毁使用sdsfree来实现 源码为： 12345/* Free an sds string. No operation is performed if 's' is NULL. */void sdsfree(sds s) &#123; if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1]));&#125; s[-1],就是指针s向后移动移位，也就是flag的位置。将s移动到sh的位置，释放sh指针也就释放了整个sds内存。 疑惑：sh指针在sdsnewlen函数中是个局部变量，在sdsnewlen函数中是自动释放的，这里并没有传递sh指针为什么也可以释放对应的空间？ 自己想了下：malloc 函数传递的参数是需要分配的内存大小(len)，返回的是指针也就是地址。free()函数只用将malloc函数返回的指针(地址)作为参数传入，就可以释放之前该地址分配到的内存空间。而地址只是首地址，总共的偏移量（大小），应该是由操作系统在内存分配的时候就记录了的。 博客中记录：申请的时候实际上占用的内存要比申请的大。因为超出的空间是用来记录对这块内存的管理信息。额外的空间用来记录管理信息——分配块的长度，指向下一个分配块的指针等等。果然malloc的时候用来一个struct来记录分配的信息。 1234struct mem_control_block &#123; int is_available; //一般来说应该是一个可用空间的首地址，但这里英文单词却显示出空间是否可用的一个标记 int size; //这是实际空间的大小 &#125;; http://www.cnblogs.com/hanyonglu/archive/2011/04/28/2031271.html free()就是根据这个结构体的信息来释放malloc()申请的空间 另外的疑惑：释放完空间后，s 指针不用把它指向null吗？ 暂时就只是创建和销毁的源码把，看了两天，阅读源码真的是酣畅淋漓，收获良多。学到了很多奇妙的C技巧，还对操作系统的知识有了更具象的理解。 参考资料https://blog.csdn.net/yangbodong22011/article/details/78419966]]></content>
      <categories>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis设计与实现读书笔记——第二章SDS]]></title>
    <url>%2F2019%2F03%2F20%2F2019-03-20-Redis%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Redis设计与实现读书笔记为了做Redis相关实验，在网上粗略看了Redis设计与实现的电子版，感觉收获很多，但是因为是旧版，所以买了第二版，重读第二次。 第二章 简单动态字符串简介 字符串值的键值对在底层都是由SDS实现的。 sds的功能： 存储字符串值 用作缓冲区 AOF模块缓冲区 客户端状态的输入缓冲区 2.1 SDS的定义文件：sds.h/sdshdr 结构体 书中的为3.0版本，4.0版本有较大改动。 version: redis-4.02 参考：https://www.cnblogs.com/chenpingzhao/p/7292182.html https://www.codesheep.cn/2018/08/09/Redis%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B%E5%86%85%E9%83%A8%E7%BC%96%E7%A0%81%E5%89%96%E6%9E%90/ 1234567891011121314151617181920212223242526272829303132typedef char *sds; //注意，sds其实不是一个结构体类型，而是被typedef的char*/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; 除了结构体字段对len和alloc的数据类型的不同(unit8, unit16， unit32, unit64)， 其字段含义相差无几。其中header记录len, alloc, flags 信息。不同的header的目的是节省内存。header与buf数组在内存地址上前后相邻。 12345+--------+-------------------------------+-----------+| Header | Binary safe C alike string... | Null term |+--------+-------------------------------+-----------+ | `-&gt; Pointer returned to the user. 1234len: 记录buf数组中已使用的字节数量 等于保存的字符串的长度 （不算结尾的\0 标识符）alloc: 字符串最大的容量。（除开header和最后的null终止符） flags: 总是会占用一个字节 8bit，加上unsigned是因为flags都是非负数 ，其中的最低3个bit用来表示header的类型还有 5个bit没有使用。buf: 字符数组，用于保存字符串。 柔性数组 buf的大小=alloc+1； header类型定义中，注意的地方： 在各个header的定义中使用了attribute ((packed))，是为了让编译器以紧凑模式来分配内存，取消字节对齐。如果没有这个属性，编译器可能会为struct的字段做优化对齐，在其中填充空字节。那样的话，就不能保证header和sds的数据部分紧紧前后相邻，也不能按照固定向低地址方向偏移1个字节的方式来获取flags字段了。 在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为柔性数组（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。 sdshdr5与其它几个header结构不同，它不包含alloc字段，而长度使用flags的高5位来存储。因此，它不能为字符串分配空余空间。如果字符串需要动态增长，那么它就必然要重新分配内存才行。所以说，这种类型的sds字符串更适合存储静态的短字符串（长度小于32）。 因为长度的范围是5个bit来存储的$$2^5-1 = 31$$ sds字符串的header，其实隐藏在真正的字符串数据的前面（低地址方向）。这样的一个定义，有如下几个好处 header和数据相邻，而不用分成两块内存空间来单独分配。这有利于减少内存碎片，提高存储效率（memory efficiency）。 虽然header有多个类型，但sds可以用统一的char *来表达。且它与传统的C语言字符串保持类型兼容。如果一个sds里面存储的是可打印字符串，那么我们可以直接把它传给C函数，比如使用strcmp比较字符串大小，或者使用printf进行打印。2.2 SDS与C字符串的区别 c语言使用N+1长度的字符数组来表示长度为N的字符串，因为需要增加一个\0 字符终止 2.2.1 常数复杂度获取字符串长度因为c语言要知道字符串的长度只能遍历数组，所以复杂度为O(N)。 而获取sds的字符串长度，只需要返回len的值就可以了复杂度为O(1)。这样对一个非常长的字符串键反复执行STRLEN命令，也不会对系统性能造成任何影响。 2.2.2 杜绝缓冲区溢出C字符串不记录自身长度会带来易造成缓冲区溢出的问题。 比如使用strcat函数拼接两个字符串，被拼接的字符串要是没有提前分配空间，就会造成缓冲区溢出。（溢出的字节会导致这个字符串内存紧邻的其他字符串的内容被修改） 而SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能，SDS的API需要修改SDS时，会先检查空间alloc是否满足修改所需的要求。不满足的话会先将空间扩展至修改所需的大小，再执行修改。 2.2.3 减少修改字符串时带来的内存重分配次数C语言字符串用N+1个字节长的数组来保存N个字节的字符串，因为这个关联性所以每次每次增长或者缩短一个C字符串，都要对这个字符串进行一次内存重分配操作。 执行增长操作 比如append，需要首先通过内存重分配来扩展底层数组的空间大小，否则产生缓冲区溢出 执行所动操作比如截断操作trime，需要首先通过内存重分配来释放字符串不再使用的空间，否则造成内存泄漏。 内存重分配涉及复杂的算法，并且可能需要执行系统调用，所以通常是一个比较耗时的操作。这对Redis经常用于速度要求严苛，数据被频繁修改的场合来说，是不可接受的。 因此SDS通过未使用空间解除了字符串长度和底层数组长度之间的关联：buf的长度可以大于len的长度。 （4.0版本的源码还未找到对应的函数，所以可能和书上说的有变化了） 空间预分配 ——减少连续执行字符串增长操作所需的内存重分配次数。 用于优化字符串增长操作。 当需要对SDS的空间进行空间扩展时，不仅会对SDS分配修改所必需的空间，还会额外分配未使用空间。 当len &lt; 1Mb时 alloc = 2*len; 当len &gt;= 1 mb时 alloc= len +1Mb。 源码分析 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ if (avail &gt;= addlen) return s; len = sdslen(s); sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); // 预分配 if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; type = sdsReqType(newlen); /* Don't use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) &#123; newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can't use realloc */ newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; memcpy((char*)newsh+hdrlen, s, len+1); s_free(sh); s = (char*)newsh+hdrlen; s[-1] = type; sdssetlen(s, len); &#125; sdssetalloc(s, newlen); return s;&#125; 惰性空间释放 用于优化SDS的字符串缩短操作 缩短SDS保存的字符串时，并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性，将这些字节的数量记录起来，并等待将来使用。 2.2.4 二进制安全C字符串中的字符必须符合某种编码（如ASCII），除了末尾字符串中间不能有\0 这个空字符，否则最先被程序读取的空字符将被认为是结尾，导致C字符串只能保存文本数据，而不能保存图片、音频、视频、压缩文件这样的二进制数据。 所谓二进制安全：以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，被读取是就是什么样的。因为SDS使用len来判断字符串是否结束。 所以buf是字节数组，而不是字符数组。 2.2.5 兼容部分C字符串函数因为遵循C字符串以\0结尾的惯例，所以可以兼容&lt;string.h&gt;/strcasecmp ,&lt;stdio.h&gt;/printf 这些函数。但是是否是书上的使用结构体指针还是博客说的可以直接使用sds来调用？还需验证。 书：printf(&quot;%s&quot;, sds-&gt;buf) sds是指向结构体的指针。 博客：https://blog.csdn.net/yangbodong22011/article/details/78419966 :printf(%s, sds) 源码中是直接使用sds 2.2.6 总结 C字符串 SDS 获取字符串长度复杂度为O(N) 获取字符串长度复杂度为O(1) API不安全，可能造成缓冲区溢出 API安全，不会造成缓冲区溢出 修改字符串长度N次必然执行N次内存重分配 最多执行N次内存重分配 只能保存文本数据 二进制安全文本与二进制数据皆可 可使用&lt;string.h&gt;库中所有函数 部分使用&lt;string.h&gt;库中函数 2.3 SDSAPI 函数 作用 sdslen(const sds s) 获取sds字符串长度 O（1） sdssetlen(sds s, size_t newlen) 设置sds字符串长度 sdsinclen(sds s, size_t inc) 增加sds字符串长度 sdsalloc(const sds s) 获取sds字符串容量 sdssetalloc(sds s, size_t newlen) 设置sds字符串容量。 sdsavail(const sds s) 获取sds字符串空余空间（即alloc - len） sdsHdrSize(char type) 根据header类型得到header大小 sdsReqType(size_t string_size) 根据字符串数据长度计算所需要的header类型。 sdsReqType函数源码分析12345678910111213static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) // string_size &lt; 2^5 return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) //string_size &lt; 2^8 return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) //string_size &lt; 2^16 return SDS_TYPE_16;#if (LONG_MAX == LLONG_MAX) if (string_size &lt; 1ll&lt;&lt;32) //string_size &lt; 2^32 return SDS_TYPE_32;#endif return SDS_TYPE_64; &#125; 采用左移来计算对应多少位的范围，而不是用2^5 这样的乘法。直接移位比使用幂来计算快很多。 1&lt;&lt;5 计算出来就是2^5 次方。1是int型，4byte32位。最低8bit位的二进制为：00000001 左移5位后变成了：00100000 对应的十进制既是32。 计算n个bit位的最大值：(1&lt;&lt;n) -1 但是需要注意位数不够的情况。因为1是int型，只有32个bit。所以在左移32个bit时，需要使用long long int型。用1ll来表示，此时1ll为64个bit。 还得考虑机器是否为64位机器，在32位机器上LONG_MAX = 2147483647L，64位机器上LONG_MAX = 9223372036854775807L 。不论32位机器还是64位机器上 LLONG_MAX 都是9223372036854775807L 。所以当LONG_MAX == LLONG_MAX 说明字长为64bit。加上条件编译，说明在32位机器上不使用sdshdr32而直接跳到了sdshdr64，仅仅在64位机器上使用sdshdr32。原因是什么？还没想通 问题 为什么Redis需要自己实现字符串功能，而不直接使用c语言的传统字符串？ 见第二节。 执行SET 与GET命令的过程。 char buf[] 为什么没有指定大小？一个数组占用的内存大小 在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为柔性数组（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。 数组内存大小为分配的的长度*数组类型的内存大小 为什么redis 在32位机器上不使用sdshdr32？]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ping 无法连接外网]]></title>
    <url>%2F2019%2F03%2F15%2Fping%20%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[ping 无法连接外网 问题ping外网ping不通 1234yky@hw076:~/tmux&gt; ping www.baidu.comping: unknown host www.baidu.comyky@hw076:~/tmux&gt; ping 8.8.8.8connect: Network is unreachable ping内网可以ping通 12345678910hw076:~ # ping 172.18.11.114PING 172.18.11.114 (172.18.11.114) 56(84) bytes of data.64 bytes from 172.18.11.114: icmp_seq=1 ttl=64 time=0.193 ms64 bytes from 172.18.11.114: icmp_seq=2 ttl=64 time=0.216 ms64 bytes from 172.18.11.114: icmp_seq=3 ttl=64 time=0.207 ms64 bytes from 172.18.11.114: icmp_seq=4 ttl=64 time=0.200 ms^C--- 172.18.11.114 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 2999msrtt min/avg/max/mdev = 0.193/0.204/0.216/0.008 ms ifconfig信息为： 12345678910111213141516171819hw076:~ # ifconfig eth0 Link encap:Ethernet HWaddr 90:E2:BA:15:C9:C4 inet addr:172.18.11.76 Bcast:192.168.1.255 Mask:255.255.0.0 inet6 addr: fe80::92e2:baff:fe15:c9c4/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:9725797 errors:0 dropped:506 overruns:0 frame:0 TX packets:21023 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:598731249 (570.9 Mb) TX bytes:2767270 (2.6 Mb) Memory:fb480000-fb500000 lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:276 errors:0 dropped:0 overruns:0 frame:0 TX packets:276 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:25088 (24.5 Kb) TX bytes:25088 (24.5 Kb) route显示路由信息如下： 1234567hw076:/etc/netconfig.d # routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault * 0.0.0.0 UG 0 0 0 eth0loopback * 255.0.0.0 U 0 0 0 lolink-local * 255.255.0.0 U 0 0 0 eth0172.18.0.0 * 255.255.0.0 U 0 0 0 eth0 原因是route没有配置网关，gateway是空着的。 解决方法通过查看其他可以正常访问的节点的路由信息，得知网关节点为：172.18.0.254。因此增加默认网关节点配置。 执行命令： 1route add default gw 172.18.0.254 再次查看路由信息： 1234567hw076:~ # routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 172.18.0.254 0.0.0.0 UG 0 0 0 eth0loopback * 255.0.0.0 U 0 0 0 lolink-local * 255.255.0.0 U 0 0 0 eth0172.18.0.0 * 255.255.0.0 U 0 0 0 eth0 再次ping8.8.8.8显示正常，问题解决。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
        <tag>网络问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用YCSB 评测redis性能]]></title>
    <url>%2F2019%2F03%2F12%2F%E4%BD%BF%E7%94%A8YCSB%20%E8%AF%84%E6%B5%8Bredis%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[使用YCSB 评测redis性能YCSB是雅虎推出的可以评测许多主流数据库性能的基准测试，其中包括Redis。 安装YCSB 安装java和maven 机子已经有了java，所以只用安装maven Ubuntu安装命令为： sudo apt-get install maven 安装YCSB 123git clone http://github.com/brianfrankcooper/YCSB.gitcd YCSBmvn -pl com.yahoo.ycsb:redis-binding -am clean package 必须是gitclone的源码包才能执行mvn 命令。wget或者curl下来包是已经编译好了的无需执行mvn命令。 mvn -pl com.yahoo.ycsb:redis-binding -am clean package 报错： 123456789[INFO] Scanning for projects...[ERROR] [ERROR] Could not find the selected project in the reactor: com.yahoo.ycsb:redis-binding @ [ERROR] Could not find the selected project in the reactor: com.yahoo.ycsb:redis-binding -&gt; [Help 1][ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.[ERROR] Re-run Maven using the -X switch to enable full debug logging.[ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles:[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MavenExecutionException 原因：此命令是在gitclone后未编译的时候使用的。而我之前是下载的编译好的tar.gz包，解压后是已经编译好了的。所以再次执行编译的命令时会报错。 使用YCSB将redis-server启动后开始使用YCSB 设置数据库需要先创建usertable的表，因为YCSB客户端默认是对usertable 进行操作。Redis将数据存储在内存中，不需要相关操作。 选择合适的DB interfaceYCSB的操作是通过DB interface来实现的。最基本的DB interface是com.yahoo.ycsb.BasicDB，会将输出输出到System.out里。可以通过继承DB interface来自定义DB interface，也可以使用原有的DB interface。Redis不需要此步操作。 选择合适的负载YCSB提供了6种负载，负载在worloads目录下。详情见https://github.com/brianfrankcooper/YCSB/wiki/Core-Workloads Workload A: Update heavy workload 读写比例为： 50/50 混合负载 Workload A: Update heavy workload 读写比例为：95/5 读为主的负载 Workload C: Read only 100% 的读 只读负载 Workload D: Read latest workload 读取最近的数据负载 Workload E: Short ranges 小范围的查询负载 Workload F: Read-modify-write 读修改写负载 自定义负载：参考https://github.com/brianfrankcooper/YCSB/wiki/Implementing-New-Workloads 可以通过修改参数文件或者新建java类来实现 需要注意的是YCSB的读写负载是针对哈希类型的数据而不是简单的字符串 指定需要的运行参数主要是指定redis的ip ，端口，密码等。 命令如下： 1./bin/ycsb load redis -s -P workloads/workloada -p &quot;redis.host=127.0.0.1&quot; -p &quot;redis.port=6379&quot; &gt; outputLoad.txt -s : status.十秒打印一次状态 加载负载命令如下： 1./bin/ycsb load redis -s -P workloads/workloada &gt; outputLoad.txt 运行负载命令如下： 1./bin/ycsb run redis -s -P workloads/workloada &gt; outputRun.txt 可以使用basic数据库来打印YCSB向数据库中写入的具体数据 12bin/ycsb.sh load basic -P workloads/workloadabin/ycsb.sh run basic -P workloads/workloada 参考https://datawine.github.io/2018/12/11/YCSB%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0/ https://github.com/brianfrankcooper/YCSB/tree/master/redis]]></content>
      <tags>
        <tag>redis</tag>
        <tag>benchmark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apt-get install失败]]></title>
    <url>%2F2019%2F03%2F10%2Fapt-get%20install%20%E5%A4%B1%E8%B4%A5%2F</url>
    <content type="text"><![CDATA[apt-get install失败 第一阶段 使用perf 报错 内核无法找到perf 12345678910root@hw103:/home/yky/redis-5.0.3# perf WARNING: perf not found for kernel 4.15.0-45 You may need to install the following packages for this specific kernel: linux-tools-4.15.0-45-generic linux-cloud-tools-4.15.0-45-generic You may also want to install one of the following packages to keep up to date: linux-tools-generic linux-cloud-tools-generic 安装此内核的通用工具时错误 1234567891011root@hw103:/home/yky/redis-5.0.3# apt-get install linux-tools-4.15.0-45-genericReading package lists... DoneBuilding dependency tree Reading state information... DoneYou might want to run &apos;apt-get -f install&apos; to correct these:The following packages have unmet dependencies: console-setup : Depends: keyboard-configuration (= 1.178ubuntu2.7) but 1.108ubuntu15.3 is to be installed console-setup-linux : Depends: keyboard-configuration (= 1.178ubuntu2.7) but 1.108ubuntu15.3 is to be installed Breaks: keyboard-configuration (&lt; 1.138) but 1.108ubuntu15.3 is to be installed linux-tools-4.15.0-45-generic : Depends: linux-tools-4.15.0-45 but it is not going to be installedE: Unmet dependencies. Try &apos;apt-get -f install&apos; with no packages (or specify a solution). 使用apt-get -f install 时报错 123456789update-rc.d: error: insserv rejected the script headerdpkg: error processing archive /var/cache/apt/archives/keyboard-configuration_1.178ubuntu2.7_all.deb (--unpack): subprocess new pre-installation script returned error exit status 1dpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installeddpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installeddpkg-query: warning: files list file for package &apos;keyboard-configuration&apos; missing; assuming package has no files currently installedErrors were encountered while processing: /var/cache/apt/archives/keyboard-configuration_1.178ubuntu2.7_all.debE: Sub-process /usr/bin/dpkg returned an error code (1) 问题综述： apt-get install lib时报错 Unmet dependencies apt-get install -f 时报错Sub-process /usr/bin/dpkg returned an error code (1) 第一阶段解决办法 在/var/lib/dpkg/目录下有个info文件 ，然后文件中没有keyboard-configuration的相关文件但是有info的备份info_backup ，这里面有相关的文件，于是将keyboard-configuration的所有相关文件都拷贝到了/var/lib/dpkg/info 中。 在info_backup目录下执行如下命令拷贝 cp keyboard-configuration.* ../info 随后再次执行安装内核通用工具 报错为第二阶段 第二阶段 安装此内核的通用工具时时报错： 123456789101112131415161718192021222324252627282930313233insserv: Starting redis depends on plymouth and therefore on system facility `$all&apos; which can not be true!insserv: exiting now without changing boot order!update-rc.d: error: insserv rejected the script headerdpkg: error processing package avahi-daemon (--configure): subprocess installed post-installation script returned error exit status 1No apport report written because MaxReports is reached already No apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of avahi-utils: avahi-utils depends on avahi-daemon; however: Package avahi-daemon is not configured yet.dpkg: error processing package avahi-utils (--configure): dependency problems - leaving unconfiguredSetting up unattended-upgrades (1.1ubuntu1.18.04.9) ...dpkg: error processing package unattended-upgrades (--configure): subprocess installed post-installation script returned error exit status 10No apport report written because MaxReports is reached already Setting up linux-tools-4.15.0-45 (4.15.0-45.48) ...Setting up linux-tools-4.15.0-45-generic (4.15.0-45.48) ...Processing triggers for initramfs-tools (0.122ubuntu8.14) ...Errors were encountered while processing: udev snapd ubuntu-core-launcher kmod ubuntu-drivers-common whoopsie openssh-server ssh avahi-daemon avahi-utils unattended-upgradesE: Sub-process /usr/bin/dpkg returned an error code (1) 解决办法：/var/lib/dpkg/info 目录下将上述出现问题的模块的postinst文件重命名。 在/var/lib/dpkg/info 下写了个脚本 solution.sh 12345#!/bin/bashfor pack in $(cat module.txt)do mv &quot;$pack&quot;.postinst &quot;$pack&quot;.postinst.bakdone 其中module.txt的内容为 1234567891011udevsnapdubuntu-core-launcherkmodubuntu-drivers-commonwhoopsieopenssh-serversshavahi-daemonavahi-utilsunattended-upgrades 执行脚本后 使用sudo apt-get upgrade 进行更新 参考： https://www.codelast.com/%E5%8E%9F%E5%88%9B-%E8%A7%A3%E5%86%B3ubuntu-%E6%97%A0%E6%B3%95%E7%94%A8-apt-get-install-%E5%AE%89%E8%A3%85%E4%BB%BB%E4%BD%95%E8%BD%AF%E4%BB%B6dpkg-error-processing-package-xxx%E7%9A%84%E9%97%AE/ https://askubuntu.com/questions/949760/dpkg-warning-files-list-file-for-package-missing]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make学习]]></title>
    <url>%2F2018%2F10%2F09%2Fmake%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[make学习开始阅读redis源码，都说redis很简单，源码不多。但是源码包下载下来后却发现不知道从何处入手，有那么多文件和源码。后面查找资料才发现阅读源码的第一步就是阅读Makefile，项目如何构建和源码间的关联都写在了Makefile文件中。之前没有接触过Makefile，记录下Make的学习。 makefile的格式 概述 makefile 文件由一系列rules组成 rules的格式为： 12&lt;target&gt; : &lt;prerequisites&gt; [tab] &lt;commands&gt; ​ “目标”是必需的，不可省略；”前置条件”和”命令”都是可选的，但是两者之中必须至少存在一个。 ​ 每条规则就明确两件事：构建目标的前置条件是什么，以及如何构建。 target 一个目标（target）就构成一条规则。目标通常是文件名，指明Make命令所要构建的对象，比如上文的 a.txt 目标可以是一个文件名，也可以是多个文件名，之间用空格分隔。（make的时候指定文件名从而对该文件进行构建build） 除了文件名，目标还可以是某个操作的名字，这称为”伪目标”（phony target）。伪目标不生成文件，只执行命令。 比如： 12clean: rm *.o 此时执行make clean 命令则会进行rm *.o 的操作。 但是当存在clean这个文件时，那么这个命令不会执行。因为Make发现clean文件已经存在，就认为没有必要重新构建了，就不会执行指定的rm命令。 为了避免这种情况，可以明确声明clean是”伪目标”，写法如下。 123.PHONY: cleanclean: rm *.o temp 如果Make命令运行时没有指定目标，默认会执行Makefile文件的第一个目标。 prerequisites 前置条件通常是一组文件名，之间用空格分隔。它指定了”目标”是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），”目标”就需要重新构建。 没有前置条件，就意味着它跟其他文件都无关，只要这个target文件还不存在 就需要执行命令构建 如果需要生成多个文件，往往采用下面的写法。 source: file1 file2 file3 无需加上命令，当三个文件不存在时，执行make source就会生成这三个文件。 commands 命令（commands）表示如何更新目标文件，由一行或多行的Shell命令组成。它是构建”目标”的具体指令，它的运行结果通常就是生成目标文件。 每行命令之前必须有一个tab键 需要注意的是，每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。 123var-lost: export foo=bar echo &quot;foo=[$$foo]&quot; 上面代码执行后（make var-lost），取不到foo的值。因为两行命令在两个不同的进程执行。 解决办法： 命令写在同1行 换行符前加反斜杠转义 123var-kept: export foo=bar; \ echo &quot;foo=[$$foo]&quot; 加上.ONESHELL:命令 1234.ONESHELL:var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; makefile的语法 注释 井号（#）在Makefile中表示注释。 回声（echoing） 正常情况下，make会打印每条命令，然后再执行，这就叫做回声（echoing）。 在命令的前面加上@，就可以关闭回声。 由于在构建过程中，需要了解当前在执行哪条命令，所以通常只在注释和纯显示的echo命令前面加上@。 通配符 由于在构建过程中，需要了解当前在执行哪条命令，所以通常只在注释和纯显示的echo命令前面加上@。 模式匹配 Make命令允许对文件名，进行类似正则运算的匹配，主要用到的匹配符是%。比如，假定当前目录下有 f1.c 和 f2.c 两个源码文件，需要将它们编译为对应的对象文件。 1%.o: %.c 等同于 12f1.o: f1.cf2.o: f2.c 使用匹配符%，可以将大量同类型的文件，只用一条规则就完成构建。 变量和赋值符 Makefile 允许使用等号自定义变量。 123txt = Hello Worldtest: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中 调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。 内置变量 Make命令提供一系列内置变量，比如，$(CC) 指向当前使用的编译器，$(MAKE) 指向当前使用的Make工具。这主要是为了跨平台的兼容性 gmake、cmake、dmake等等。 自动变量 $@指代当前目标，就是Make命令当前构建的那个目标 target $&lt;指代第一个前置条件。比如，规则为 t: p1 p2，那么$&lt; 就指代p1 $？指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，$?就指代p2。 $^指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 $^ 就指代 p1 p2 。 $指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$ 就表示 f1。 $(@D) 和 $(@F)$(@D) 和 $(@F) 分别指向 $@ 的目录名和文件名。比如，$@是 src/input.c，那么$(@D) 的值为 src ，$(@F) 的值为 input.c。 $(&lt;D) 和 $(&lt;F) $(&lt;D) 和 $(&lt;F) 分别指向 $&lt; 的目录名和文件名。 其他 .DEFAULT：表示找不到匹配规则时，就执行该recipe。 123default:all.DEFAULT: commands 这里当执行make default 时会转到make all 因为default：all 这个target没有隐式规则。所以最后会执行commands。 忽略命令的出错，可以在Makefile的命令行前加一个减号”-“(在Tab键之后)，标记为不管命令出不出错都认为是成功的。如： 12clean: -(rm -f *.o ) include filename 将filename中的内容导入，如果找不到会停止make， -include filename 则不会停止make。 参考资料： http://www.ruanyifeng.com/blog/2015/02/make.html https://gist.github.com/isaacs/62a2d1825d04437c6f08 makefile文件教程 https://www.gnu.org/software/make/manual/make.html GNUmake手册]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令学习之wc]]></title>
    <url>%2F2018%2F07%2F09%2FLinux%20%E5%91%BD%E4%BB%A4%20%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Linux 命令学习wc命令wc命令 作用：Word Count 功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 格式： wc [option] filepath 参数 -c 统计字节数 -l 统计行数 -m 统计字符数 标志不能与 -c 标志一起使用。 -w 统计字（单词word）数。一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度。 -help 显示帮助信息 --version 显示版本信息 参考网址：http://www.cnblogs.com/peida/archive/2012/12/18/2822758.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[make 2>&1 | tee log.txt 命令解析]]></title>
    <url>%2F2018%2F06%2F23%2Ftee%E5%91%BD%E4%BB%A4%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[make 2&gt;&amp;1 | tee log.txt 命令解析在安装mpich 的时候遇到了很多这个命令，此处学习下这个命令：2&gt;&amp;1 | tee log.txt 这个命令共有三个部分： 2&gt;&amp;1 | tee log.txt 2&gt;&amp;1shell中：最常使用的 FD (file descriptor) 大概有三个 0表示标准输入Standard Input (STDIN) 1表示标准输出Standard Output (STDOUT) 2表示标准错误输出 Standard Error Output (STDERR) ‘&gt;’ 默认为标准输出重定向 （类似于c++ 中的 &gt;&gt;？） 在标准情况下, 这些FD分别跟如下设备关联 stdin(0): keyboard 键盘输入,并返回在前端 stdout(1): monitor 正确返回值 输出到前端 stderr(2): monitor 错误返回值 输出到前端 1&gt;&amp;2 正确返回值传递给2输出通道 &amp;2表示2输出通道 如果此处错写成 1&gt;2, 就表示把1输出重定向到文件2中 2&gt;&amp;1 错误返回值传递给1输出通道, 同样&amp;1表示1输出通道. |管道管道的作用是提供一个通道，将上一个程序的标准输出重定向到下一个程序作为下一个程序的标准输入。 tee log.txttee从标准输入中读取，并将读入的内容写到标准输出以及文件中。 此处将数据读入并写入到log.txt中 总结这个命令将标准错误输出重定向到标准输出，然后再将标准输出重定向到log.txt文件中 常用于make 后面将log信息保存下来。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BigdataBench deploy]]></title>
    <url>%2F2018%2F06%2F23%2FBigdataBench-deploy%2F</url>
    <content type="text"><![CDATA[Bigdatabench 4.0 MPI版本 安装 官网上面的指南BigDataBench User Manual有一些错误。 本机环境： ​ Centos 6.9 ​ gcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15) ​ g++ (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15) mpi的安装这部分网上资料很多，而Manual中有一点错误 需要保证c 编译器 如gcc c++ 编译器 如：g++ 基础安装 从官网下载安装包解压 wget http://www.mpich.org/static/downloads/3.2.1/mpich-3.2.1.tar.gz 从官网下载安装包 tar -zxvf mpich-3.2.1.tar.gz 解压 cd mpich-3.2.1 配置安装目录 本机安装在mpich-install目录下 ./configure –prefix=/home/mpich-install 2&gt;&amp;1 | tee c.txt 手册中&amp;被错写为$了 2&gt;&amp;1 | tee c.txt 表示将输出的标准出错信息重定向到c.txt中。 build make 2&gt;&amp;1 | tee m.txt 安装 make install 2&gt;&amp;1 | tee mi.txt 将安装目录添加到PATH 环境变量中 vim ~/.bashrc export PATH=$PATH:/home/mpich-install/bin 在最后一行添加 source ~/.bashrc 重启生效 检查 检查路径 which mpicc which mpic++ 验证 在mpich的安装包目录下有提供例子程序运行 cd mpich-3.2.1/examples mpicc cpi.c -o cpi 编译cpi.c程序求pi值 mpirun -n 4 ./cpi 使用4个进程 注意./否则报错找不到文件 如果是集群环境在每个节点将mpich安装在相同的路径然后编辑一个machine_file （里面是各个节点的host）然后mpirun -f machine_file -n 3 ./cpi 在集群上并行运行 boost 安装boost当前最新版本是：1.67 但是BigdataBench用的是1.43版本推荐安装这个旧版本 wget https://sourceforge.net/projects/boost/files/boost/1.43.0/boost_1_43_0.tar.gz/download 若下载下来的文件名为：downloads 则使用mv命令重命名在当前文件目录下: mv downloads boost_1_43_0.tar.gz 解压tar -zxvf boost_1_43_0.tar.gz 之后cd boost_1_43_0 sh bootstrap.sh 执行这个命令运行脚本后会多出很多配置文件 使用mpi,这一步骤很重要否则后续cmake时会提示找不到：boost_mpi 对低版本的boost which mpic++ 找mpich的目录 vim tools/build/v2/user-config.jam 在最后添加： using mpi:后面是mpich的目录 #MPI config using mpi : /usr/lib64/mpich/bin/mpic++ ; 对高版本的boost直接在boost_1_67_0目录下修改project-config.jam即可 ./bjam 进行编译 ./bjam install 这一步是必需的但在手册中没有表明。 BigdataBench的配置进入BigDataBench的安装根目录： vim conf.properties 添加$JAVA_HOME， $MPI_HOME ，$BigdataBench_HOMEMPI的路径 sh prepar.sh 至此安装理论上已经成功。但仍然遇到了其他问题 Perminsion denied问题最开始的安装包是从windows下面考过去的结果生成cc的数据后无法运行执行脚本 原因是此时的run_connectedComponents已经不是可执行文件了（不是绿色的）需要chmod a+x run_connectedComponents来将文件的权限修改为可执行文件权限（修改后变为绿色） 后面wget下载后解压配置之后直接就是可执行文件！ ldd 程序 动态链接库缺失[root@hw073 ConnectedComponent]# ldd run_connectedComponentslinux-vdso.so.1 =&gt; (0x00007ffdfc8d4000)librt.so.1 =&gt; /lib64/librt.so.1 (0x0000003156e00000)libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x0000003156a00000) libboost_serialization-mt.so.1.43.0 =&gt; not foundlibboost_filesystem-mt.so.1.43.0 =&gt; not foundlibboost_system-mt.so.1.43.0 =&gt; not foundlibstdc++.so.6 =&gt; /usr/lib64/libstdc++.so.6 (0x0000003162200000)libm.so.6 =&gt; /lib64/libm.so.6 (0x0000003157200000)libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x0000003161a00000)libc.so.6 =&gt; /lib64/libc.so.6 (0x0000003156600000)/lib64/ld-linux-x86-64.so.2 (0x0000003155e00000) 最开始以为是没有指定LD_LIBRARY_PATH ，因为明明有这个文件的，后面使用find / -name 命令发现还是找不到，仔细一看ldd 的信息，发现上述文件都多了个-mt 解决办法： 在boost安装时的库。本机：/usr/local/lib 有着及其相似的3个文件libboost_filesystem.so.1.43.0 、libboost_filesystem.so.1.43.0 ，libboost_system.so.1.43.0 均少了个-mt，因此将上述三个文件均拷贝一份命名为上述缺少的动态库文件。 cd /usr/local/lib #切换到对应的目录下 cp libboost_system.so.1.43.0 libboost_system-mt.so.1.43.0 #拷贝为对应的文件名]]></content>
      <categories>
        <category>deploy</category>
      </categories>
      <tags>
        <tag>bigdatabench</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图计算常用算法]]></title>
    <url>%2F2018%2F04%2F24%2F%E5%9B%BE%E8%AE%A1%E7%AE%97%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[图算法的典型操作关于一些常见图算法的调研与学习。 常用图算法PageRank 背景 既考虑入链数量，又考虑了网页质量因素，二者相结合 数量与权重的结合 算法与主题无关，因为PR值是根据图计算出来的 算法原理 基本思想 A有链接指向B，表明A认为B比A重要。A将自身权重分配一部分给B。 $W(B)=W(A)/N$ W(A) 是A的PR值，W(B)是A 分配的权重，N是A的出链数 PageRank公式修正 存在出链为0的孤立网页，增加阻力系数q ，一般取q=0.85，其意义是用户有1-q的概率不点击此页面上面的所有链接。同时还有随机直接跳转的概率，如直接输入网址，点击书签等。完整公式如下： Connected component 定义 连通分支：图中，某个子图的任意两点有边连接，而子图之间无边连接 问题：cc是寻找连通分支的算法？？ 通过BFS、DFS算法的便利就可以找到连通分支，每个白色节点开始的就是一个连通分支。 常见算法 DFS 原理：访问某个顶点后只有当某个节点是叶结点后才会访问其余相邻节点。 步骤： 选择一个结点作为起始结点，标记为灰色 从该节点的邻居结点中选择一个结点，标记为灰色，继续这个操作 当选中的结点时叶子结点时，将其涂黑并返回到上一个父节点。 重复2,3直到所有结点都被访问。 BFS （DFS，BFS不是图的遍历算法吗）。 原理：在进一步遍历中顶点之前，先访问当前结点的所有邻接结点。 步骤： 选择一个顶点作为起始节点，放入队列，标记为灰色，其余标记为白色 寻找队列首部结点的所有邻居节点，将其放入队列中并标记为灰色，将队列首部结点出队，并标记为黑色 重复2步骤，直到队列中的节点全部为空。 SSSP (single-source shortest paths) 单独的起点与目标点之间最短路径的计算。起点固定，寻找与其他所有结点之间的最短路径。包括单源单汇，单源多汇 常见算法 Dijkstra 步骤 将所有顶点分成两个集合A、B，其中集合A表示已经求得从V0出发的最短路径的顶点集合，集合B为为待求解的顶点集合。初始时有A={V0} 将集合A与集合B相连的边（A中的所有结点与B中所有的结点形成的边）按照从V0出发的最短权重和递增次序排序，取最短的边，将该条边在集合B中所对应的顶点加入到集合A中 重复第二步，直至B为空集。 总结： 最短中的最短：每次迭代时比较的是当前状态下以V0为起点，A中顶点为中间点的到各顶点之间的最短路径权重，最后再选择在当前所有最短路径中路径最短的一个顶点加入A。也就是说每次加入A集合的点是最短路径中的最短。 给定目标点，在每次迭代时，并不知道能否到达最后的目标点，所以把到所有结点的最短距离都算出来了。 Betweenness Centrality（中介中心性） 定义 ：中心性用来衡量节结点的重要性。Betweenness Centrality ：考虑的是该节点出现在其他两节点之间的最短路径上的比率。 思想：如果一个成员位于其他成员的多条最短路上，那么该成员就是核心成员，就具有较大的中介中心性。 步骤 其中表示的是节点s和t之间的最短路径的数量，而是最短路径中经过节点v的数量。 计算各个点对之间最短路径的长度和条数，用于计算pair-dependencies: δst(v) =σst(v)/σst 对于每个节点，累积属于自己的pair-dependencies LBP算法(Local Binary Pattern, 局部二值模式) 定义：LBP是一种用来描述图像局部纹理特征的算子。 原始的LBP算子定义为在3*3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0 作用是进行特征提取，而且，提取的特征是图像的纹理特征，并且，是局部的纹理特征. 改进版本 原型LBP算子 LBP等价模式 最小生成树 定义：无环连通图，图中所有结点均参与，所有边的权重加起来最小。 算法 Prim算法 步骤：设N=(V,{E})是连通网， TE是N上最小生成树中边的集合 初始令U={u0},(u0V), TE=φ 在所有uU,vV-U的边(u,v)E中，找一条代价最小的边(u0,v0), 并保证不形成回路 将(u0,v0)并入集合TE，同时v0并入U 重复上述操作直至U=V为止，则T=(V,{TE})为N的最小生成树 总结：每次迭代加入所有连通边中权值最小的。 三角计数 定义：寻找无向图中的所有三角形 步骤 建立邻接表： 如果A-B &amp; A &lt; B，则将B加入A的邻接表 如果A-B &amp; B &lt; A，则将A加入B的邻接表 A&lt;B比较的是id 遍历每个节点，对于结点A，遍历A邻接表中的结点，如果邻接结点B,C两两之间存在边，则A、B、C三者之间存在三角形 社区发现 社区定义：同一社区内的节点与节点之间的连接很紧密，而社区与社区之间的连接比较稀疏。社区是一个子图 数学描述： 衡量标准：模块度 计算公式 常见算法 GN算法 思想：在一个网络之中，通过社区内部的边的最短路径相对较少，而通过社区之间的边的最短路径的数目则相对较多。从社区内部走大概率会走很多条边。 步骤 计算每一条边的边介数。边介数（betweenness）：网络中任意两个节点通过此边的最短路径的数目。 删除边介数最大的边 重复（1）（2），直到网络中的任一顶点作为一个社区为止。 缺陷 不知道最后会有多少个社区 在计算边介数的时候可能会有很对重复计算最短路径的情况，时间复杂度太高 GN算法不能判断算法终止位置 LPA算法（标签传播算法） 思路 自己是什么标签，由邻居决定。邻居中什么标签最多，则此结点是什么标签 步骤 为所有结点指定一个唯一的标签 逐轮刷新所有结点的标签，直到达到收敛要求位置。刷新规则： 对于某一个节点，考察其所有邻居节点的标签，并进行统计，将出现个数最多的那个标签赋给当前节点。当个数最多的标签不唯一时，随机选一个。 拓扑排序 定义 ：拓扑排序（Topological Sorting）是一个有向无环图（DAG, Directed Acyclic Graph）的所有顶点的线性序列。且该序列必须满足下面两个条件： 每个顶点出现且只出现一次 若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面 步骤 从 DAG 图中选择一个 没有前驱（即入度为0）的顶点并输出 从图中删除该顶点和所有以它为起点的有向边 重复 1 和 2 直到当前的 DAG 图为空或当前图中不存在无前驱的顶点为止。后一种情况说明有向图中必然存在环]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph 部署文档]]></title>
    <url>%2F2018%2F04%2F17%2Fceph%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[ceph 部署文档 1.配置所有节点创建ceph用户安装配置NTP systemctl enable ntp ubuntu 14.04不可用，感觉已经安装过了，因此跳过。 配置hosts文件172.16.1.93 object1172.16.1.94 object2172.16.1.95 object3172.16.1.66 object4172.16.1.92 controller 2. 配置ssh服务器修改ssh的配置文件 Host controller Hostname gd92 User cephuserHost object1 Hostname gd93 User cephuserHost object2 Hostname hw101 User cephuserHost object3 Hostname gd95 User cephuserHost object4 Hostname gd66 User cephuser 生成密钥并拷贝到4个osd节点上，无需拷贝到controller节点 3安装ceph主要参考链接：这些链接的操作大都一致，部分的顺序会有变化。 https://linux.cn/article-8182-1.html#4_10238 https://blog.csdn.net/styshoo/article/details/55471132 https://blog.csdn.net/styshoo/article/details/58572816 部署监控节点出现的问题ceph-deploy mon create-initial ceph-mon --cluster ceph --mkfs -i gd92 --keyring /var/lib/ceph/tmp/ceph-gd92.mon.keyring 问题：ceph.conf的配置文件中的public network=172.16.1.92/24 掩码前面多打了空格 修改后重新执行命令，并加上--overwrite-conf [info]Running command: ceph –cluster=ceph –admin-daemon /var/run/ceph/ceph-mon.controller.asok mon_status admin_socket: exception getting command descriptions: [Errno 2] No such file or directory 似乎是ceph -deploy 的问题，或者是ubuntu14.04的问题。教程是ubuntu16.04的 此问题非hostname 不对应 非conf 不同步导致。–overwrtie-conf 无作用。 解决办法：按照14.04方法重新安装ceph-deploy 部署osd节点出现的问题 使用ceph-deploy disk list ceph-osd1 ceph-osd2 ceph-osd3检查磁盘可用性时报错，使用ceph-deploy osd prepare ceph-osd1:/dev/sdb ceph-osd2:/dev/sdb ceph-osd3:/dev/sdb 在数据盘上面准备时也报错Running command: fdisk -l File “/usr/lib/python2.7/distpackages/ceph_deploy/util/decorators.py”, line 69, in newfunc问题：未知解决办法：将osd节点的数据目录放在指定目录，不用整个数据盘 最后部署后集群状况是health -ok，但是4osds，有3个osd up，一个osd down问题：down掉的节点磁盘有问题。解决办法：先卸载磁盘，重新格式化，挂载，重新激活osd节点 部署rgw节点出现的问题 显示rgw进程在工作，但是使用：http://controller:7480 显示拒绝连接。并且新建S3账号，测试时未返回正确结果。 问题：未知 尝试方法：重新部署 解决办法：重新部署后最开始将端口设置为80，发现可以创建s3账号，但是无法正确测试，显示创建bucket出错，查看rgw的log，发现端口被占用，无法打开，后面重新设置端口为7480问题解决，测试均正确。]]></content>
      <categories>
        <category>deploy</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
</search>
